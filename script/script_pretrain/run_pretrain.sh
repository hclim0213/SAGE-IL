python run_pretrain.py --model_type LSTM --dataset zinc --dataset_path /workspace/_ext/data/datasets/zinc --max_smiles_length 100 --hidden_size 1024 --dropout 0.2 --n_layers 3 --num_epochs 50 --batch_size 1024 --save_root /workspace/_ext/data/pretrained_models/models/ --use_cuda --num_workers 1 --seed 404 > SAGE_Pretrain_LSTM_M100_B1024_E50_ZINC.log
python run_pretrain.py --model_type Transformer --dataset zinc --dataset_path /workspace/_ext/data/datasets/zinc --max_smiles_length 100 --hidden_size 1024 --dropout 0.2 --n_layers 3 --n_head 8 --embed_size 256 --num_epochs 50 --batch_size 512 --save_root /workspace/_ext/data/pretrained_models/models/ --use_cuda --num_workers 1 --seed 404 > SAGE_Pretrain_Transformer_M100_B512_E50_ZINC.log
python run_pretrain.py --model_type TransformerDecoder --dataset zinc --dataset_path /workspace/_ext/data/datasets/zinc --max_smiles_length 100 --hidden_size 1024 --dropout 0.2 --n_layers 3 --n_head 8 --embed_size 256 --num_epochs 50 --batch_size 512 --save_root /workspace/_ext/data/pretrained_models/models/ --use_cuda --num_workers 1 --seed 404 > SAGE_Pretrain_TransformerDecoder_M100_B512_E50_ZINC.log
